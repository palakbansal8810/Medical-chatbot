# Medical-chatbot

A **Retrieval-Augmented Generation (RAG) medical chatbot** built with **Flask, Pinecone, and Groq LLM**. This project allows users to ask health-related questions and receive accurate, context-aware answers from a curated medical knowledge base.

---

## ğŸš€ Features

* **Flask Web App** â€“ User-friendly interface for real-time chat.
* **RAG Pipeline** â€“ Uses a retriever to fetch context from a Pinecone vector database.
* **LLM Integration** â€“ Powered by **Groq's `gemma2-9b-it` model** for intelligent, conversational responses.
* **Similarity Search** â€“ Ensures top-3 relevant chunks are retrieved for precise answers.
* **Environment Secure** â€“ API keys and configurations are stored using `.env` for safety.
## ğŸ“‚ Project Structure

```
Medical-chatbot/
â”‚
â”œâ”€â”€ app.py                # Main Flask application
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ helper.py         # Helper functions (e.g., downloading embeddings)
â”‚   â”œâ”€â”€ prompt.py         # System and conversation prompts
â”‚
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html        # Frontend interface
â”‚
â”œâ”€â”€ .env                  # Environment variables (API keys)
â”œâ”€â”€ requirements.txt      # Python dependencies
â””â”€â”€ README.md             # Project documentation
```

---

## âš™ï¸ Setup and Installation

### 1ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/palakbansal8810/Medical-chatbot.git
cd Medical-chatbot
```

### 2ï¸âƒ£ Create and Activate Virtual Environment

```bash
python -m venv venv
source venv/bin/activate   # Mac/Linux
venv\Scripts\activate      # Windows
```

### 3ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

### 4ï¸âƒ£ Set Up Environment Variables

Create a `.env` file in the root directory:

```bash
PINECONE_API_KEY=your_pinecone_api_key
GROQ_API_KEY=your_groq_api_key
```

### 5ï¸âƒ£ Run the Application

```bash
python app.py
```

Visit the app at **[http://localhost:8000](http://localhost:8000)** in your browser.

---

## ğŸ§  How It Works

1. **User Query** â†’ User inputs a medical question.
2. **Retriever** â†’ Searches Pinecone for similar, relevant embeddings.
3. **LLM Chain** â†’ Groq LLM uses the retrieved content to generate a contextual answer.
4. **Response** â†’ The chatbot displays the answer on the web interface.

---


